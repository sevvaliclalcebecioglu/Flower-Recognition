{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88dc65f-55bf-443d-8a83-7316b3ca1e48",
   "metadata": {},
   "source": [
    "# _Flower Recognition - Classification Project_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e98be59-82f0-4710-9211-901b39e8f313",
   "metadata": {},
   "source": [
    "<img src='../data/flower.webp'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71b6be-415c-4751-ae77-1e52da1516f8",
   "metadata": {},
   "source": [
    "_Bu proje, **Python ve makine öğrenmesi** kullanarak çiçek görsellerini tanımaya odaklanmaktadır. Amaç, bir çiçek fotoğrafını renk ve kenar özelliklerine göre **beş sınıftan birine** sınıflandırmaktır._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ca6ef-b412-4dd4-a117-5b5ab9904f2c",
   "metadata": {},
   "source": [
    "## _Veri Seti_\n",
    "- _Toplam **4242 çiçek görseli** içeriyor._\n",
    "- _Görseller **Flickr, Google Görseller ve Yandex Görseller**den toplandı._\n",
    "- _**5 sınıf mevcut:**_\n",
    "  - _Papatya (Chamomile)_\n",
    "  - _Lale (Tulip)_\n",
    "  - _Gül (Rose)_\n",
    "  - _Ayçiçeği (Sunflower)_\n",
    "  - _Karahindiba (Dandelion)_\n",
    "- _Görseller düşük çözünürlüklü (~320x240) ve farklı boyutlarda._\n",
    "\n",
    "## _Adımlar_\n",
    "1. _**Veri Hazırlığı**_\n",
    "   - _Görseller ve etiketler yüklenir._\n",
    "   - _Gerekirse görseller standart boyuta getirilir._\n",
    "   - _Görseller ML modellerinin anlayacağı şekilde diziye çevrilir._ <br><br>\n",
    "\n",
    "2. _**Özellik Çıkarımı**_\n",
    "   - _Görsellerin renk ve kenar özellikleri kullanılır._\n",
    "   - _Örnekler: HOG özellikleri, renk histogramları veya doğrudan piksel değerleri._ <br><br>\n",
    "\n",
    "3. _**Eğitim/Test Bölme**_\n",
    "   - _Veri seti eğitim ve test olarak ayrılır._ <br><br>\n",
    "\n",
    "4. _**Model Eğitimi**_\n",
    "   - _Kullanılabilecek modeller:_\n",
    "     - _Random Forest, SVM, KNN veya_\n",
    "     - _Derin öğrenme için Convolutional Neural Network (CNN)_\n",
    "   - _Model eğitim verisi ile eğitilir._ <br><br>\n",
    "\n",
    "5. _**Model Değerlendirme**_\n",
    "   - _Doğruluk (accuracy), precision, recall gibi metrikler ile performans değerlendirilir._\n",
    "   - _Yanlış sınıflandırılan görseller gözlemlenir._ <br><br>\n",
    "\n",
    "6. _**Tahmin**_\n",
    "   - _Eğitilen model kaydedilir._\n",
    "   - _Yeni bir görselin sınıfı tahmin edilir._ <br><br>\n",
    "\n",
    "7. _**Streamlit Arayüzü**_\n",
    "   - _Kullanıcı çiçek görseli yükleyebilir ve model tahminini görebilir._ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e9b986-81c4-4d27-812f-b902f496e46b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### _İmport_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c8a5f52-8df3-4bcc-ad39-01bc5f6fb2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV kütüphanesini import ediyoruz, görüntü işleme ve video/frame işlemleri için kullanılır\n",
    "import cv2\n",
    "\n",
    "# Pandas kütüphanesini import ediyoruz, veri analizi ve tablo şeklinde veri yönetimi için kullanılır\n",
    "import pandas as pd\n",
    "\n",
    "# NumPy kütüphanesini import ediyoruz, sayısal hesaplamalar ve matris işlemleri için kullanılır\n",
    "import numpy as np\n",
    "\n",
    "# scikit-learn kütüphanesinden train_test_split fonksiyonunu import ediyoruz,\n",
    "# veriyi eğitim ve test setlerine ayırmak için kullanılır\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Keras kütüphanesinden gerekli modülleri import ediyoruz\n",
    "# Sequential: katman katman model oluşturmak için\n",
    "# Conv2D: 2D evrişim katmanı (görüntülerde özellik çıkarımı için)\n",
    "# Dense: tam bağlantılı katman (sınıflandırma veya regresyon için)\n",
    "# Flatten: çok boyutlu veriyi tek boyuta indirger\n",
    "# Input: modelin giriş katmanı\n",
    "# MaxPooling2D: evrişim katmanından sonra boyut küçültmek için max pooling uygular\n",
    "# Dropout: aşırı öğrenmeyi (overfitting) önlemek için rastgele nöronları kapatır\n",
    "# BatchNormalization: modelin daha hızlı ve stabil öğrenmesini sağlar\n",
    "# Reshape: verinin şeklini değiştirmek için\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, Input, MaxPooling2D, Dropout, BatchNormalization, Reshape\n",
    "\n",
    "# İşletim sistemi ile ilgili işlemler yapmak için os modülünü import ediyoruz\n",
    "# Örneğin dosya/dizin kontrolleri, dosya yolları oluşturma gibi\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57505b15-cdc9-4b44-8cfd-b179a8216c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python'da uyarı mesajlarını yönetmek için warnings modülünü import ediyoruz\n",
    "import warnings\n",
    "\n",
    "# Tüm uyarı mesajlarını görmezden gelmek için filterwarnings ile 'ignore' ayarını yapıyoruz\n",
    "# Bu sayede ekranda gereksiz uyarılar görünmez ve kod çıktısı daha temiz olur\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edeeb7b-5514-4d24-8288-6092ef122329",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### _Eda_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37965a83-2a39-4122-8383-1df4f7ab370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sınıf etiketlerini bir liste halinde tanımlıyoruz\n",
    "# 'Cancer' -> Kanserli örnekler\n",
    "# 'Non_Cancer' -> Kanserli olmayan örnekler\n",
    "labels = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
    "\n",
    "# Görüntülerin bulunduğu ana dizin yolunu belirtiyoruz\n",
    "# Bu klasör içinde 'Cancer' ve 'Non_Cancer' alt klasörleri olabilir\n",
    "img_path = '../data/flowers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6bb28dc-1af8-4e79-a923-e6248066b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d8a155-c8b1-485f-b7f9-eaa690fd18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boş bir liste oluşturuyoruz; görüntülerin dosya yollarını buraya ekleyeceğiz\n",
    "img_list = []\n",
    "\n",
    "# Boş bir liste oluşturuyoruz; her görüntüye karşılık gelen etiketi buraya ekleyeceğiz\n",
    "label_list = []\n",
    "\n",
    "# labels listesindeki her sınıf (ör. 'Cancer' ve 'Non_Cancer') için döngü\n",
    "for label in labels:\n",
    "    \n",
    "    # Her sınıfın klasöründeki tüm dosyaları listele\n",
    "    for img_file in os.listdir(img_path + label):\n",
    "        \n",
    "        # Görüntü dosyasının tam yolunu oluştur ve img_list'e ekle\n",
    "        img_list.append(img_path + label + \"/\" + img_file)\n",
    "        \n",
    "        # Görüntünün ait olduğu sınıf etiketini label_list'e ekle\n",
    "        label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4427a98-189d-4875-903b-85e2d4642732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_list ve label_list listelerini kullanarak bir DataFrame oluşturuyoruz\n",
    "# DataFrame, tablo şeklinde veri tutmamızı sağlar (sütunlar: 'img' ve 'label')\n",
    "df = pd.DataFrame({'img': img_list,  # 'img' sütunu: görüntü dosya yolları\n",
    "                   'label': label_list})  # 'label' sütunu: her görüntünün sınıf etiketi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c864a66d-f859-4bb8-91ce-cd37a3e7164a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/flowers/daisy/100080576_f52e8ee070_n.jpg</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/flowers/daisy/10140303196_b88d3d6cec.jpg</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/flowers/daisy/10172379554_b296050f82_n...</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/flowers/daisy/10172567486_2748826a8b.jpg</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/flowers/daisy/10172636503_21bededa75_n...</td>\n",
       "      <td>daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>../data/flowers/tulip/9831362123_5aac525a99_n.jpg</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>../data/flowers/tulip/9870557734_88eb3b9e3b_n.jpg</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314</th>\n",
       "      <td>../data/flowers/tulip/9947374414_fdf1d0861c_n.jpg</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>../data/flowers/tulip/9947385346_3a8cacea02_n.jpg</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>../data/flowers/tulip/9976515506_d496c5e72c.jpg</td>\n",
       "      <td>tulip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4317 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    img  label\n",
       "0      ../data/flowers/daisy/100080576_f52e8ee070_n.jpg  daisy\n",
       "1      ../data/flowers/daisy/10140303196_b88d3d6cec.jpg  daisy\n",
       "2     ../data/flowers/daisy/10172379554_b296050f82_n...  daisy\n",
       "3      ../data/flowers/daisy/10172567486_2748826a8b.jpg  daisy\n",
       "4     ../data/flowers/daisy/10172636503_21bededa75_n...  daisy\n",
       "...                                                 ...    ...\n",
       "4312  ../data/flowers/tulip/9831362123_5aac525a99_n.jpg  tulip\n",
       "4313  ../data/flowers/tulip/9870557734_88eb3b9e3b_n.jpg  tulip\n",
       "4314  ../data/flowers/tulip/9947374414_fdf1d0861c_n.jpg  tulip\n",
       "4315  ../data/flowers/tulip/9947385346_3a8cacea02_n.jpg  tulip\n",
       "4316    ../data/flowers/tulip/9976515506_d496c5e72c.jpg  tulip\n",
       "\n",
       "[4317 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ed6866-df77-4e96-a7e0-9831503483cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sınıf isimlerini sayısal değerlere eşleyecek bir sözlük oluşturuyoruz\n",
    "# Çiçek isimlerini sayılara eşleme\n",
    "d = {\n",
    "    'daisy': 0,\n",
    "    'dandelion': 1,\n",
    "    'rose': 2,\n",
    "    'sunflower': 3,\n",
    "    'tulip': 4\n",
    "}\n",
    "\n",
    "# DataFrame'deki 'label' sütununu sayısal değerlere çeviriyoruz\n",
    "# map fonksiyonu, her etiketi sözlükteki karşılığı ile değiştirir\n",
    "df['label_encoded'] = df['label'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8ac82ef-c853-42f4-8715-d651a1622292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/flowers/daisy/100080576_f52e8ee070_n.jpg</td>\n",
       "      <td>daisy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/flowers/daisy/10140303196_b88d3d6cec.jpg</td>\n",
       "      <td>daisy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/flowers/daisy/10172379554_b296050f82_n...</td>\n",
       "      <td>daisy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/flowers/daisy/10172567486_2748826a8b.jpg</td>\n",
       "      <td>daisy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/flowers/daisy/10172636503_21bededa75_n...</td>\n",
       "      <td>daisy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>../data/flowers/tulip/9831362123_5aac525a99_n.jpg</td>\n",
       "      <td>tulip</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>../data/flowers/tulip/9870557734_88eb3b9e3b_n.jpg</td>\n",
       "      <td>tulip</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314</th>\n",
       "      <td>../data/flowers/tulip/9947374414_fdf1d0861c_n.jpg</td>\n",
       "      <td>tulip</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315</th>\n",
       "      <td>../data/flowers/tulip/9947385346_3a8cacea02_n.jpg</td>\n",
       "      <td>tulip</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>../data/flowers/tulip/9976515506_d496c5e72c.jpg</td>\n",
       "      <td>tulip</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4317 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    img  label  label_encoded\n",
       "0      ../data/flowers/daisy/100080576_f52e8ee070_n.jpg  daisy              0\n",
       "1      ../data/flowers/daisy/10140303196_b88d3d6cec.jpg  daisy              0\n",
       "2     ../data/flowers/daisy/10172379554_b296050f82_n...  daisy              0\n",
       "3      ../data/flowers/daisy/10172567486_2748826a8b.jpg  daisy              0\n",
       "4     ../data/flowers/daisy/10172636503_21bededa75_n...  daisy              0\n",
       "...                                                 ...    ...            ...\n",
       "4312  ../data/flowers/tulip/9831362123_5aac525a99_n.jpg  tulip              4\n",
       "4313  ../data/flowers/tulip/9870557734_88eb3b9e3b_n.jpg  tulip              4\n",
       "4314  ../data/flowers/tulip/9947374414_fdf1d0861c_n.jpg  tulip              4\n",
       "4315  ../data/flowers/tulip/9947385346_3a8cacea02_n.jpg  tulip              4\n",
       "4316    ../data/flowers/tulip/9976515506_d496c5e72c.jpg  tulip              4\n",
       "\n",
       "[4317 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "\n",
    "#Oluşturduğumuz dataframein tamamını görüntüleyebiliriz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf3c494-bddb-45e0-b37d-ecb93bb8155c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### _Classification_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51cad6ff-321b-4dd7-8538-d091c0058cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boş bir liste oluşturuyoruz; işlenmiş görüntüleri buraya ekleyeceğiz\n",
    "x = []  \n",
    "\n",
    "# DataFrame'deki tüm görüntü dosya yolları üzerinde döngü\n",
    "for img in df['img']:\n",
    "    \n",
    "    # Görüntüyü OpenCV ile oku\n",
    "    img = cv2.imread(str(img))\n",
    "    \n",
    "    # Görüntüyü 170x170 boyutuna yeniden boyutlandır\n",
    "    # Not: ResNet transfer learning kullanacağımız için 170x170 girdik\n",
    "    # Ama başka projelerde yeterli RAM varsa istediğimiz başka boyutu da kullanabiliriz\n",
    "    img = cv2.resize(img, (170, 170))\n",
    "    \n",
    "    # Piksel değerlerini normalize et (0-1 aralığına getir)\n",
    "    img = img / 255.0\n",
    "    \n",
    "    # İşlenmiş görüntüyü listeye ekle\n",
    "    x.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ded8e909-d2af-4a44-9e84-3e8060910ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x listesini NumPy dizisine çeviriyoruz\n",
    "# Çünkü makine öğrenmesi ve derin öğrenme kütüphaneleri genellikle NumPy dizileri ile çalışır\n",
    "x = np.array(x)  # Artık x, modelin anlayacağı şekilde çok boyutlu bir dizi (array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb9379bd-54ea-4415-9ddf-2ddd2ac16f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4317, 170, 170, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5af0846-686d-4097-b8b4-584fb9858f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame'den sadece 'label_encoded' sütununu seçiyoruz\n",
    "# Bu sütun, her görüntünün sayısal sınıf etiketini (0 veya 1) içeriyor\n",
    "y = df[['label_encoded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b65d1b4-3cf2-4373-8541-0e896377b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veriyi eğitim ve test setlerine ayırıyoruz\n",
    "# x → görüntü verileri (girdi)\n",
    "# y → etiketler (çıktı)\n",
    "# test_size=0.20 → verinin %20'si test seti, %80'i eğitim seti olacak\n",
    "# random_state=42 → rastgele bölme işleminin tekrarlanabilir olmasını sağlar\n",
    "#                  42 sadece farklı bir sabit sayı, aynı sayıyı her kullanışta aynı bölme elde edilir\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30afd7b9-1dbc-4619-a20a-e6acf2f06a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim etiketlerini NumPy dizisine çeviriyoruz ve veri tipini int32 olarak belirliyoruz\n",
    "y_train = np.array(y_train, dtype=np.int32)\n",
    "\n",
    "# Test etiketlerini NumPy dizisine çeviriyoruz ve veri tipini int32 olarak belirliyoruz\n",
    "y_test = np.array(y_test, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ab95e53-0277-4c19-aed8-196c73f5b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model oluşturuyoruz, katman katman model ekleyebileceğiz\n",
    "model = Sequential()\n",
    "\n",
    "# Modelin giriş katmanını tanımlıyoruz\n",
    "# Girdi boyutu: 170x170 piksel, 3 renk kanalı (RGB)\n",
    "model.add(Input(shape=(170, 170, 3)))\n",
    "\n",
    "# 1. Convolution (evrişim) katmanı\n",
    "# 32 filtre, 3x3 boyutunda, aktivasyon fonksiyonu ReLU\n",
    "# Görüntüden özellikler çıkarır\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# 1. MaxPooling katmanı\n",
    "# 2x2 boyutunda, uzaysal boyutları küçültür ve hesaplamayı azaltır\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# 2. Convolution katmanı\n",
    "# 64 filtre, 3x3 boyutunda, aktivasyon fonksiyonu ReLU\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# 2. MaxPooling katmanı\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten katmanı\n",
    "# Çok boyutlu veriyi tek boyuta indirger, Dense katmanına girdi olarak verir\n",
    "model.add(Flatten())\n",
    "\n",
    "# Tam bağlantılı (Dense) katman\n",
    "# 128 nöron, ReLU aktivasyonu\n",
    "# Görüntüden çıkarılan özellikleri birleştirir ve öğrenir\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Çıkış katmanı\n",
    "# 1 nöron, sigmoid aktivasyonu\n",
    "# Binary classification için 0-1 arasında tahmin verir\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Modeli derliyoruz\n",
    "# optimizer='adam' → ağırlıkları güncellemek için Adam optimizasyonu\n",
    "# loss='binary_crossentropy' → binary sınıflandırma için uygun kayıp fonksiyonu\n",
    "# metrics=['accuracy'] → eğitimi izlerken doğruluk metriğini hesaplar\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "107b6db3-9033-437d-b603-75aeeb4e97ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 168ms/step - accuracy: 0.3698 - loss: 1.7534 - val_accuracy: 0.4965 - val_loss: 1.2835\n",
      "Epoch 2/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 162ms/step - accuracy: 0.6015 - loss: 1.0340 - val_accuracy: 0.5671 - val_loss: 1.1288\n",
      "Epoch 3/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 164ms/step - accuracy: 0.7396 - loss: 0.7053 - val_accuracy: 0.5938 - val_loss: 1.1506\n",
      "Epoch 4/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 165ms/step - accuracy: 0.8810 - loss: 0.3749 - val_accuracy: 0.5949 - val_loss: 1.4030\n",
      "Epoch 5/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 160ms/step - accuracy: 0.9545 - loss: 0.1655 - val_accuracy: 0.5451 - val_loss: 1.9236\n",
      "Epoch 6/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 164ms/step - accuracy: 0.9763 - loss: 0.0994 - val_accuracy: 0.5683 - val_loss: 2.0146\n",
      "Epoch 7/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 167ms/step - accuracy: 0.9806 - loss: 0.0763 - val_accuracy: 0.5532 - val_loss: 2.2086\n",
      "Epoch 8/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 163ms/step - accuracy: 0.9904 - loss: 0.0549 - val_accuracy: 0.5845 - val_loss: 2.1038\n",
      "Epoch 9/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 162ms/step - accuracy: 0.9887 - loss: 0.0549 - val_accuracy: 0.5613 - val_loss: 2.2505\n",
      "Epoch 10/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 169ms/step - accuracy: 0.9907 - loss: 0.0431 - val_accuracy: 0.5359 - val_loss: 2.6265\n",
      "Epoch 11/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 163ms/step - accuracy: 0.9930 - loss: 0.0340 - val_accuracy: 0.5752 - val_loss: 2.5177\n",
      "Epoch 12/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 163ms/step - accuracy: 0.9965 - loss: 0.0241 - val_accuracy: 0.5718 - val_loss: 2.8667\n",
      "Epoch 13/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 165ms/step - accuracy: 0.9986 - loss: 0.0169 - val_accuracy: 0.5799 - val_loss: 2.6640\n",
      "Epoch 14/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 168ms/step - accuracy: 0.9988 - loss: 0.0116 - val_accuracy: 0.5891 - val_loss: 2.7685\n",
      "Epoch 15/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 161ms/step - accuracy: 0.9986 - loss: 0.0116 - val_accuracy: 0.5880 - val_loss: 2.7816\n",
      "Epoch 16/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 158ms/step - accuracy: 0.9988 - loss: 0.0099 - val_accuracy: 0.5891 - val_loss: 2.9878\n",
      "Epoch 17/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 160ms/step - accuracy: 0.9988 - loss: 0.0110 - val_accuracy: 0.5926 - val_loss: 2.7647\n",
      "Epoch 18/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 163ms/step - accuracy: 0.9988 - loss: 0.0104 - val_accuracy: 0.6019 - val_loss: 2.6009\n",
      "Epoch 19/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 160ms/step - accuracy: 0.9986 - loss: 0.0067 - val_accuracy: 0.5926 - val_loss: 2.6889\n",
      "Epoch 20/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 161ms/step - accuracy: 0.9983 - loss: 0.0087 - val_accuracy: 0.6019 - val_loss: 2.5610\n"
     ]
    }
   ],
   "source": [
    "# Modeli eğitim verisiyle eğitiyoruz\n",
    "history = model.fit(\n",
    "    x_train,              # Girdi verileri (görüntüler)\n",
    "    y_train,              # Hedef etiketler (0 veya 1)\n",
    "    validation_data=(x_test, y_test),  # Her epoch sonunda test verisi ile doğrulama\n",
    "    epochs=20,            # Modelin tüm eğitim verisi üzerinden 20 kez geçmesi\n",
    "    verbose=1             # Eğitim sırasında ilerleme çubuğunu göster\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1dfeb1-230d-4912-be13-e53b8ee4c6b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### _Save the Model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db0314d8-e7f7-456b-92c3-88fb3b159171",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('flower_recognition_model.keras') # huggine kaydetmek istiyorsam .h5 ile kaydetmem lazım"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b9d51-fe9b-49e4-bbf3-92ecf582d3a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### _Transfer Learning_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55bdba-7dac-42e4-8219-9542d2e054fe",
   "metadata": {},
   "source": [
    "_Akıllı insan aklını kullanandır. Daha da akıllı insan başkalarınında aklını kullanandır_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc98f2-e480-49e0-beb2-5740b8d70754",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### _İmport_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d91a22d7-ca29-451e-af0d-c808c2675722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras'ın hazır transfer learning modellerini import ediyoruz\n",
    "# VGG16 ve ResNet50, önceden ImageNet veri setinde eğitilmiş derin CNN modelleridir\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "\n",
    "# Görüntü verilerini işlemek ve artırmak (augmentation) için ImageDataGenerator sınıfını import ediyoruz\n",
    "# Örneğin: döndürme, yakınlaştırma, kaydırma gibi işlemlerle eğitim verisini zenginleştirmek için kullanılır\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd9aeca-b37e-4d4a-aaa6-e4271e77d868",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### _İmport Another Model - Classification_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa2cf10b-d467-4139-8411-b8408ef021e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3457 images belonging to 5 classes.\n",
      "Found 860 images belonging to 5 classes.\n",
      "Epoch 1/5\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 2s/step - accuracy: 0.6468 - loss: 2.0861 - val_accuracy: 0.8000 - val_loss: 0.5370\n",
      "Epoch 2/5\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 2s/step - accuracy: 0.8776 - loss: 0.3581 - val_accuracy: 0.7895 - val_loss: 0.5753\n",
      "Epoch 3/5\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 2s/step - accuracy: 0.9387 - loss: 0.1808 - val_accuracy: 0.8174 - val_loss: 0.5248\n",
      "Epoch 4/5\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 2s/step - accuracy: 0.9876 - loss: 0.0692 - val_accuracy: 0.8081 - val_loss: 0.5491\n",
      "Epoch 5/5\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 2s/step - accuracy: 0.9980 - loss: 0.0296 - val_accuracy: 0.8151 - val_loss: 0.5577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fdfa85ab10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ana veri klasörünün yolunu belirliyoruz\n",
    "data_dir = '../data/flowers'\n",
    "\n",
    "# Modelin girdi boyutunu belirliyoruz (224x224 piksel)\n",
    "img_width, img_heigth = 224, 224\n",
    "\n",
    "# Eğitim verisi için ImageDataGenerator oluşturuyoruz\n",
    "# rescale=1/255 → piksel değerlerini 0-1 aralığına normalize ediyor\n",
    "# validation_split=0.20 → verinin %20'sini doğrulama için ayırıyor\n",
    "train_datagen = ImageDataGenerator(rescale=1/255, validation_split=0.20)\n",
    "\n",
    "# Eğitim verilerini klasörden okuyup artırma ve hazırlama\n",
    "train_datagenerator = train_datagen.flow_from_directory(\n",
    "    directory=data_dir,              # Ana veri klasörü\n",
    "    target_size=(img_width,img_heigth),  # Görüntüleri 224x224 boyutuna getir\n",
    "    class_mode='categorical',             # categorical sınıflandırma\n",
    "    subset='training'                # Eğitim verisi olarak ayır\n",
    ")\n",
    "\n",
    "# Test/verifikasyon verilerini hazırlıyoruz\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Doğrulama verilerini klasörden alıyoruz\n",
    "test_datagenerator = train_datagen.flow_from_directory(\n",
    "    directory=data_dir,\n",
    "    target_size=(img_width,img_heigth),\n",
    "    class_mode='categorical',\n",
    "    subset='validation'              # Doğrulama seti\n",
    ")\n",
    "\n",
    "# Önceden eğitilmiş VGG16 modelini yükle\n",
    "# weights='imagenet' → ImageNet üzerinde önceden eğitilmiş ağırlıklar\n",
    "# include_top=False → son sınıflandırma katmanını dahil etme (kendi katmanlarımızı ekleyeceğiz)\n",
    "base_model = VGG16(weights='imagenet', input_shape=(img_width,img_heigth,3), include_top=False)\n",
    "\n",
    "# Yeni bir Sequential model oluşturuyoruz\n",
    "model = Sequential()\n",
    "model.add(base_model)  # Önceden eğitilmiş VGG16 tabanını ekliyoruz\n",
    "\n",
    "# VGG16 tabanındaki tüm katmanları donduruyoruz, yani eğitim sırasında güncellenmeyecek\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Kendi üst katmanlarımızı ekliyoruz\n",
    "model.add(Flatten())            # Çok boyutlu özellik haritasını tek boyuta çevir\n",
    "model.add(Dense(1024, activation='relu'))  # Fully connected katman, öğrenilen özellikleri birleştir\n",
    "model.add(Dense(5, activation='softmax'))  # Çıkış katmanı, softmax sınıflandırma\n",
    "\n",
    "# Modeli derliyoruz\n",
    "model.compile(\n",
    "    optimizer='adam',                 # Ağırlıkları güncellemek için Adam optimizasyonu\n",
    "    loss='categorical_crossentropy',       # categorical_crossentropy sınıflandırma kayıp fonksiyonu\n",
    "    metrics=['accuracy']              # Eğitim ve doğrulama sırasında doğruluk metriğini takip et\n",
    ")\n",
    "\n",
    "# Modeli eğitim verisiyle eğitiyoruz ve doğrulama verisiyle test ediyoruz\n",
    "# epochs=10 → veri üzerinden 10 kez geçiyoruz\n",
    "model.fit(\n",
    "    train_datagenerator,\n",
    "    epochs=5,\n",
    "    validation_data=test_datagenerator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2e20c9-871b-491c-beb3-5b6989f3156c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### _Save the Transfer Learning Model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64384d0a-a12b-46b5-a63a-8a0ebbdd6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('flower_recognition_transfer_learning.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
